# Deep Q-Network for Atari DemonAttack

PyTorch implementation of Deep Q-Networks (DQN) and its variants for mastering the Atari game DemonAttack.

---

## ğŸ“‹ Overview

**DemonAttack** is a classic Atari 2600 game where the player defends against waves of demons. This project trains RL agents to play the game from raw pixel inputs.

**Benchmarks:**
- Random: ~50 | Human avg: ~1,971 | Human expert: ~3,401
- DQN: ~150 | Dueling DQN: ~600 | Noisy Dueling DQN: ~1,000+

**Implemented Models:**
- Baseline DQN (Mnih et al., 2015)
- Dueling DQN (Wang et al., 2016)
- Noisy Dueling DQN (Fortunato et al., 2017)
- Optional: Double DQN, Prioritized Experience Replay

---

## ğŸš€ Quick Start

### Installation

```bash
# Using uv (recommended)
uv sync

# Or using pip
pip install -e .
```

### Training

```bash
# Baseline DQN (500k steps, ~2-4 hours)
uv run train --config configs/baseline_dqn.yaml

# Dueling DQN (2M steps, ~8-12 hours, recommended)
uv run train --config configs/dueling_dqn.yaml

# Noisy Dueling DQN (3M steps, ~15-20 hours, best performance)
uv run train --config configs/noisy_dueling_dqn.yaml
```

### Evaluation

```bash
# Evaluate trained model
uv run eval --ckpt runs/dueling_dqn/checkpoints/final.pt --episodes 10

# Watch agent play
uv run watch --ckpt runs/dueling_dqn/checkpoints/final.pt --mode human
```

### Visualization

```bash
# Plot training curves
uv run viz --log runs/dueling_dqn/train_log.csv
```

### Web GUI

```bash
uv run web  # Open http://localhost:5000
```

Real-time monitoring, video recording, training curves, and model evaluation.

---

## âš™ï¸ Configuration

| Config | Model | Steps | Time (GPU) | Score |
|--------|-------|-------|------------|-------|
| `baseline_dqn.yaml` | DQN | 500k | 2-4h | ~150 |
| `dueling_dqn.yaml` â­ | DuelingDQN | 2M | 8-12h | ~600 |
| `noisy_dueling_dqn.yaml` ğŸ† | NoisyDuelingDQN | 3M | 15-20h | ~1000+ |

Key hyperparameters: `lr=2.5e-4`, `batch_size=64`, `replay_size=200k`, `target_update_freq=2k`

---

## ğŸ“Š Expected Results

| Method | Score | Steps | Time |
|--------|-------|-------|------|
| Random | ~50 | - | - |
| Baseline DQN | ~150 | 500k | 2-4h |
| Dueling DQN | ~400-600 | 2M | 8-12h |
| Noisy Dueling DQN | ~800-1000+ | 3M | 15-20h |
| Human Average | ~1,971 | - | - |

---

## ğŸ“ Project Structure

```
RL-DemonAttack/
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â”œâ”€â”€ baseline_dqn.yaml        # Nature DQN baseline
â”‚   â”œâ”€â”€ dueling_dqn.yaml         # Dueling architecture (recommended)
â”‚   â””â”€â”€ noisy_dueling_dqn.yaml   # Best performance
â”‚
â”œâ”€â”€ src/dqn_demon_attack/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ models.py            # DQN architectures
â”‚   â”‚   â””â”€â”€ replay.py            # Experience replay buffers
â”‚   â”œâ”€â”€ envs/
â”‚   â”‚   â””â”€â”€ wrappers.py          # Environment preprocessing
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â”‚   â”œâ”€â”€ logger.py            # Training logging
â”‚   â”‚   â””â”€â”€ viz.py               # Visualization tools
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ train.py             # Training script
â”‚   â”‚   â”œâ”€â”€ eval.py              # Evaluation script
â”‚   â”‚   â””â”€â”€ watch.py             # Visualization script
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ app.py               # Flask application
â”‚       â”œâ”€â”€ training_manager.py  # Training session management
â”‚       â”œâ”€â”€ evaluation_manager.py # Evaluation management
â”‚       â””â”€â”€ templates/
â”‚           â””â”€â”€ index.html       # Web interface
â”‚
â”œâ”€â”€ runs/                         # Training outputs
â”‚   â””â”€â”€ <exp_name>/
â”‚       â”œâ”€â”€ config.yaml          # Saved configuration
â”‚       â”œâ”€â”€ train_log.csv        # Training metrics
â”‚       â””â”€â”€ checkpoints/         # Model checkpoints
â”‚
â”œâ”€â”€ pyproject.toml               # Dependencies
â””â”€â”€ README.md                    # This file
```
